{
  "cells": [
    {
      "metadata": {
        "id": "OJgbnpkhL5ec"
      },
      "cell_type": "markdown",
      "source": [
        "# CS6493 - Tutorial 1\n",
        "## Introduction to JupyterHub and PyTorch\n",
        "\n",
        "Welcome to CS6493 tutorial. In this tutorial, you will get familiar with our exprimental environment, and also practice with some basic PyTorch operations.\n",
        "\n",
        "## 1. JupyterHub\n",
        "\n",
        "You can use the JupyterHub to run the toy models. Here are some notes for JupyterHub:\n",
        "\n",
        "- You are supposed to be familiar with Python and Jupyter;\n",
        "- We use **Google Colab** to do the following experiments, please login with your Gmail Account in https://colab.research.google.com/ (If you do not have one, please register one);\n",
        "- Please turn to Edit->Notebook Settings, and select Python 3 and GPU as the hardware accelerator;\n",
        "- Before run a specific model, please know the exact resource that you need and the resource you have with **!nvidia-smi**;\n",
        "- We are glad to provide help during the whole tutorial if you have any questions.\n",
        "\n",
        "## 2. PyTorch\n",
        "\n",
        "We use [PyTorch](https://pytorch.org/) framework to finish the implementations. In this section, we will introduce the installation, the basic operations of PyTorch.\n",
        "\n",
        "### 2.1 Installation\n",
        "Since the Colab has installed the PyTorch by default, you can check the version of PyTorch and whether it supports to GPUs by the following command."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gAa8I7e_pOK-"
      }
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep6RulJBL5ef",
        "outputId": "47ef6666-043b-421e-f181-cd9b14451ca6"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 14 02:33:28 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "execution_count": 2,
      "source": [
        "# check the GPU resource in the Colab\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeoF0CYlL5ef",
        "outputId": "2ac687f4-4941-45c1-b911-3e5ad026f2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version:  2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"PyTorch version: \", torch.__version__)"
      ]
    },
    {
      "metadata": {
        "id": "tMKVbYGkL5ef"
      },
      "cell_type": "markdown",
      "source": [
        "Additionally, if you want a specific torch version if some of the repos that requires, you can go to the Pytorch official website to find the version. And a full command with concrete version information is recommended like this:\n",
        "```\n",
        "# CUDA 12.1\n",
        "pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "y2E7RDngL5ef"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# you can try this if you want to install a specific version of PyTorch\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "metadata": {
        "id": "aLZJP1ZaL5ef"
      },
      "cell_type": "markdown",
      "source": [
        "You can use the following code to check more details about the information of GPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnrdnyxcL5eg",
        "outputId": "d9b44a2d-da39-4eff-ee6e-8b963cbf9743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version:  2.5.1+cu121\n",
            "GPU support:  True\n",
            "Available devices count:  1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"PyTorch version: \", torch.__version__)\n",
        "print(\"GPU support: \", torch.cuda.is_available())\n",
        "print(\"Available devices count: \", torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhYH18c7L5eg"
      },
      "source": [
        "## 2.2 Quick start - Tensor in PyTorch\n",
        "\n",
        "In this section, we introcue some basic concepts and operations of Tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8H8cT4DL5eg"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "metadata": {
        "id": "KfVr8AwZL5eg"
      },
      "cell_type": "markdown",
      "source": [
        "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators.\n",
        "\n",
        "One simple way to understand / utilize the tensor is to know how each dimension represents for.\n",
        "\n",
        "### Create Tensors\n",
        "\n",
        "Tensors can be created directly from data or NumPy arrays. You can assign the data type to the tensor. Otherwise, the data type would be automatically inferred."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONcA-utEL5eh",
        "outputId": "f620d9be-ed1e-430c-bcd4-32b8e6658912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Long Tensor: \n",
            " tensor([[0, 1],\n",
            "        [2, 3]]) \n",
            "\n",
            "Float Tensor: \n",
            " tensor([[0., 1.],\n",
            "        [2., 3.]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = [[0,1], [2,3]]\n",
        "tensor_data = torch.tensor(data)\n",
        "tensor_data_float = torch.tensor(data).float()\n",
        "print(f\"Long Tensor: \\n {tensor_data} \\n\")  # the data type is LongTensor\n",
        "print(f\"Float Tensor: \\n {tensor_data_float} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSuUyeQ9L5eh",
        "outputId": "73044ff1-620a-43f8-cf61-4aa566f503a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Long Tensor: \n",
            " tensor([[0, 1],\n",
            "        [2, 3]]) \n",
            "\n",
            "Float Tensor: \n",
            " tensor([[0., 1.],\n",
            "        [2., 3.]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "np_data = np.array(data)\n",
        "tensor_np_data = torch.tensor(np_data)\n",
        "tensor_np_data_float = torch.tensor(np_data).float()\n",
        "print(f\"Long Tensor: \\n {tensor_np_data} \\n\")  # the data type is LongTensor\n",
        "print(f\"Float Tensor: \\n {tensor_np_data_float} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to7CllgDL5eh"
      },
      "source": [
        "You can also create the tensors filled with constant (e.g., 0 and 1) or random values,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_P1G3q6L5eh",
        "outputId": "cae67565-521b-4413-e6c2-df24499fd455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.8107, 0.6311, 0.1082],\n",
            "        [0.0881, 0.4793, 0.0343]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "zeros_tensor = torch.zeros((2,3))\n",
        "ones_tensor = torch.ones((2,3))\n",
        "random_tensor = torch.rand((2,3))\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Random Tensor: \\n {random_tensor} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODlwBP40L5eh"
      },
      "source": [
        "### Attributes of a Tensor\n",
        "\n",
        "Tensor attributes describe their shape, datatype, and the device on which they are stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg9RLh4sL5eh",
        "outputId": "32916ad0-54cc-4e16-fe11-8f71e44de4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([2, 3])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(2,3)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vve-2ESBL5eh"
      },
      "source": [
        "### Operations on Tensors\n",
        "\n",
        "There are over 100 tensor operations, including arthmetic, linear algebra, matrix manipulation and more. In this section, we only introduce some frequently used operations in our later tutorials and projects.\n",
        "\n",
        "**Move Tensor to Device**\n",
        "\n",
        "By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using `.to()` method (after checking for GPU availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJbfSPm8L5eh",
        "outputId": "7870d19f-851b-4c5f-806b-3c0d31fef378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# move tensor to GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "tensor = tensor.to(device)\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgE79kKPL5eh"
      },
      "source": [
        "**Tensor indexing, slicing and reshape**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-06T14:53:42.140075Z",
          "start_time": "2025-01-06T14:53:29.975453Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oT5hy6-L5ei",
        "outputId": "4ae997de-d7f4-4352-f008-b41b610e572a"
      },
      "source": [
        "import torch\n",
        "tensor = torch.rand(4, 6)\n",
        "tensor"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1444, 0.1404, 0.6457, 0.3260, 0.3766, 0.6086],\n",
              "        [0.5304, 0.9665, 0.8526, 0.4024, 0.1897, 0.8329],\n",
              "        [0.0054, 0.0091, 0.7874, 0.5189, 0.8398, 0.3064],\n",
              "        [0.2892, 0.0357, 0.5813, 0.9860, 0.4902, 0.4146]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-JIlutLL5ei",
        "outputId": "ec48fe6d-3826-48f2-92b4-20f56c18b92b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([0.1444, 0.1404, 0.6457, 0.3260, 0.3766, 0.6086])\n",
            "First column: tensor([0.1444, 0.5304, 0.0054, 0.2892])\n",
            "Last column: tensor([0.6086, 0.8329, 0.3064, 0.4146])\n"
          ]
        }
      ],
      "source": [
        "# let take a look at its first row and column\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:,0]}\")\n",
        "print(f\"Last column: {tensor[:, -1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_14JHR6IL5ei",
        "outputId": "b000f5e7-4551-4499-d351-fcd013647f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshape to (2,12): \n",
            " tensor([[0.1444, 0.1404, 0.6457, 0.3260, 0.3766, 0.6086, 0.5304, 0.9665, 0.8526,\n",
            "         0.4024, 0.1897, 0.8329],\n",
            "        [0.0054, 0.0091, 0.7874, 0.5189, 0.8398, 0.3064, 0.2892, 0.0357, 0.5813,\n",
            "         0.9860, 0.4902, 0.4146]]) \n",
            "\n",
            "Reshape to (2,2,6): \n",
            " tensor([[[0.1444, 0.1404, 0.6457, 0.3260, 0.3766, 0.6086],\n",
            "         [0.5304, 0.9665, 0.8526, 0.4024, 0.1897, 0.8329]],\n",
            "\n",
            "        [[0.0054, 0.0091, 0.7874, 0.5189, 0.8398, 0.3064],\n",
            "         [0.2892, 0.0357, 0.5813, 0.9860, 0.4902, 0.4146]]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# reshape\n",
        "print(f\"Reshape to (2,12): \\n {tensor.view(2, 12)} \\n\")\n",
        "print(f\"Reshape to (2,2,6): \\n {tensor.view(-1, 2, 6)} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmt8mMejL5ei"
      },
      "source": [
        "**Joining tensors.** You can use torch.cat to concatenate a sequence of tensors along a given dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF6BfDGJL5ei",
        "outputId": "bfcce8a2-01f9-43ca-fd97-3a3561208acd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1444, 0.1404, 0.6457, 0.3260, 0.3766, 0.6086, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.5304, 0.9665, 0.8526, 0.4024, 0.1897, 0.8329, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0054, 0.0091, 0.7874, 0.5189, 0.8398, 0.3064, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.2892, 0.0357, 0.5813, 0.9860, 0.4902, 0.4146, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "t1 = torch.zeros(4, 2)\n",
        "new_t = torch.cat([tensor, t1, t1], dim=1)\n",
        "new_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNUWPBDwL5ei"
      },
      "source": [
        "**Arithmetic operations**\n",
        "\n",
        "The basic arithmetic operations of Pytorch are similar with those in Numpy, such as `.pow()`, `.div()`, `.sum()` and more. Here we talk more about multiplication in Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXBr3XfoL5ei",
        "outputId": "e655fcc9-1ea2-421f-ae86-1523376e52da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of original tensor: torch.Size([4, 6])\n",
            "Shape of matrix multiplication resulting tensor: torch.Size([4, 4])\n",
            "Shape of element-wise product resulting tensor: torch.Size([4, 6])\n"
          ]
        }
      ],
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2 will have the same value\n",
        "print(f\"Shape of original tensor: {tensor.shape}\")\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "print(f\"Shape of matrix multiplication resulting tensor: {y1.shape}\")\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "print(f\"Shape of element-wise product resulting tensor: {z1.shape}\")"
      ]
    },
    {
      "metadata": {
        "id": "0squq_4BL5ei"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.3 Practice\n",
        "\n",
        "In NLP, we have a very popular and famous techique, termed **Attention** which is used to measure the improtance among each components. Formally, we define the attention mechanism as:\n",
        "\n",
        "$Attention(\\mathbf{Q},\\mathbf{K},\\mathbf{V}) = \\text{Softmax}(\\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d_k}})\\mathbf{V}$\n",
        "\n",
        "$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$,\n",
        "\n",
        "you can attempt to implement softmax function and attention by yourself.\n",
        "\n",
        "Hint: you can decompose the equation into some basic components and check how to achieve these basic components. Google your questions and you can find the answers on stackoverflow or official documentations of Numpy or Pytorch."
      ]
    },
    {
      "metadata": {
        "id": "fINKUL-TL5ej"
      },
      "cell_type": "markdown",
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lHm3-BQL5ej"
      },
      "outputs": [],
      "source": [
        "# please notice that we have a batch size of 2,\n",
        "# and the dimension of Q, K, V is 4x8\n",
        "# you can regard them as 4 queries, 4 keys and 4 values with the representation of 8 dimensional vectors\n",
        "v= torch.rand((2,4,8))\n",
        "k = v\n",
        "q = torch.rand((2,4,8))\n",
        "d_k = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FVKbXc2L5ej"
      },
      "outputs": [],
      "source": [
        "# insert your code\n",
        "def attention(q, k, v):\n",
        "    pass\n",
        "\n",
        "def softmax(x):\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer for the practice\n",
        "## Hint: we can decompose the equation and write the logic process first, then search for the implementation"
      ],
      "metadata": {
        "id": "prIO_c3gpPln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# please notice that we have a batch size of 2,\n",
        "# and the dimension of Q, K, V is 4x8\n",
        "# you can regard them as 4 queries, 4 keys and 4 values with the representation of 8 dimensional vectors\n",
        "\n",
        "# random initialization for further test\n",
        "v= torch.rand((2,4,8))\n",
        "k = v\n",
        "q = torch.rand((2,4,8))\n",
        "d_k = 8\n",
        "\n",
        "# prepare the test case for validation\n",
        "# for simple check, we use the batch size of 1 and matrix size of (2, 4)\n",
        "# please notice the dtype should be float\n",
        "v_test = [[[1.0, 2.0, 3.0, 1.0], [2.0, 2.0, 4.0,3.0]]]\n",
        "v_test = torch.tensor(v_test)\n",
        "k_test = v_test\n",
        "q_test = [[[4.0,2.0,1.0, 4.0], [7.0,2.0, 5.0, 6.0]]]\n",
        "q_test = torch.tensor(q_test)\n",
        "# check for the data shape\n",
        "print(v_test.shape, k_test.shape, q_test.shape)\n",
        "d_k_test = 4 # the sqrt of d_k is 2 for easy testing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8afZrmGvpdFv",
        "outputId": "075b58ab-bc25-4b84-c2e1-a7a0010b08f8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2, 4]) torch.Size([1, 2, 4]) torch.Size([1, 2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! Notice That: Since this is this is the first time we practice with Pytorch, so we provide a very detailed process for you, which includes\n",
        "# -- decomposition about the task/equation\n",
        "# -- the corresponding code for implementation, validation and cross-check\n",
        "# -- the intermediate thinking process\n",
        "\n",
        "# We may not provide such details for the following tasks and leave the thinking and exploration space for yourself :)\n",
        "# If you have any questions, find any errors or have any suggestions, please feel freely to contact us.\n",
        "\n",
        "\n",
        "import math\n",
        "def attention(q, k, v):\n",
        "    # we highly recommend the using of torch method with official document illustration\n",
        "    # do the matrix mulplication first, notice the transpose\n",
        "    # check the shape of the transpose of k if you are not sure about the method\n",
        "    # - torch.transpose(k, 1, 2).shape\n",
        "\n",
        "    # decompose the equation\n",
        "    # molecular = torch.matmul(q, torch.transpose(k, 1, 2))\n",
        "    # denominator = math.sqrt(k.shape[-1])\n",
        "    # soft_result = softmax(molecular / denominator)\n",
        "    # final result = torch.matmul(soft_result, v)\n",
        "\n",
        "    # combine the above together\n",
        "    attn_compute = torch.matmul(softmax(torch.matmul(q, torch.transpose(k, 1, 2)) / math.sqrt(k.shape[-1]), -1), v)\n",
        "    return attn_compute\n",
        "\n",
        "def softmax(x, dim_):\n",
        "    # decompose the equation into two parts\n",
        "    # 1. get the exp of each element\n",
        "    # 2. get the summation of the exp of all elements (in a matrix) and do the division\n",
        "    # you can check you own soft max with the torch.nn.functional.softmax\n",
        "    # !!! one thing we need to know is that the softmax is not on the whole matrix but on a specific dimension, usually the last dimension\n",
        "    exp_x = torch.exp(x)\n",
        "    sum_x = torch.sum(exp_x, dim_, keepdim=True)\n",
        "    return exp_x / sum_x"
      ],
      "metadata": {
        "id": "TWSXC2MjqWe9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the softmax implementation\n",
        "exp_own = softmax(v, -1)\n",
        "exp_torch = torch.nn.functional.softmax(v, dim=-1)\n",
        "print(exp_own)\n",
        "print(exp_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVq_UGIksjiA",
        "outputId": "bf3f570b-7aa7-4145-fa74-3a9f28f30a1f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.1164, 0.1182, 0.1174, 0.1730, 0.0948, 0.1464, 0.1248, 0.1089],\n",
            "         [0.0823, 0.1113, 0.1495, 0.1220, 0.1117, 0.1010, 0.1832, 0.1390],\n",
            "         [0.1228, 0.1672, 0.1130, 0.1723, 0.1109, 0.0665, 0.1086, 0.1387],\n",
            "         [0.2289, 0.1224, 0.1217, 0.0889, 0.1226, 0.0875, 0.1016, 0.1264]],\n",
            "\n",
            "        [[0.1281, 0.1507, 0.0901, 0.0806, 0.0802, 0.1052, 0.1586, 0.2065],\n",
            "         [0.1283, 0.1416, 0.0766, 0.1503, 0.1468, 0.0767, 0.1697, 0.1099],\n",
            "         [0.1172, 0.1628, 0.1011, 0.1316, 0.1827, 0.0762, 0.1497, 0.0787],\n",
            "         [0.0967, 0.0737, 0.1237, 0.1412, 0.1617, 0.1593, 0.0983, 0.1453]]])\n",
            "tensor([[[0.1164, 0.1182, 0.1174, 0.1730, 0.0948, 0.1464, 0.1248, 0.1089],\n",
            "         [0.0823, 0.1113, 0.1495, 0.1220, 0.1117, 0.1010, 0.1832, 0.1390],\n",
            "         [0.1228, 0.1672, 0.1130, 0.1723, 0.1109, 0.0665, 0.1086, 0.1387],\n",
            "         [0.2289, 0.1224, 0.1217, 0.0889, 0.1226, 0.0875, 0.1016, 0.1264]],\n",
            "\n",
            "        [[0.1281, 0.1507, 0.0901, 0.0806, 0.0802, 0.1052, 0.1586, 0.2065],\n",
            "         [0.1283, 0.1416, 0.0766, 0.1503, 0.1468, 0.0767, 0.1697, 0.1099],\n",
            "         [0.1172, 0.1628, 0.1011, 0.1316, 0.1827, 0.0762, 0.1497, 0.0787],\n",
            "         [0.0967, 0.0737, 0.1237, 0.1412, 0.1617, 0.1593, 0.0983, 0.1453]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the code\n",
        "attn_result = attention(q,k,v)\n",
        "# check with official method\n",
        "attn_official = torch.nn.functional.scaled_dot_product_attention(q, k, v)\n",
        "print(attn_result)\n",
        "print(attn_official)\n",
        "\n",
        "# you can use the test data as well for intermediate process checking\n",
        "print(attention(q_test, k_test, v_test))\n",
        "print(torch.nn.functional.scaled_dot_product_attention(q_test, k_test, v_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWxp6MNeyyUQ",
        "outputId": "43a2f51a-ec48-46f1-8c5b-2dee7a41113e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.5415, 0.5852, 0.5622, 0.6506, 0.4228, 0.3014, 0.5880, 0.5845],\n",
            "         [0.5435, 0.6083, 0.5669, 0.6708, 0.4330, 0.2850, 0.5912, 0.5998],\n",
            "         [0.5381, 0.5992, 0.5638, 0.6743, 0.4251, 0.3037, 0.5907, 0.5903],\n",
            "         [0.5368, 0.6034, 0.5660, 0.6776, 0.4278, 0.3002, 0.5935, 0.5943]],\n",
            "\n",
            "        [[0.5038, 0.5648, 0.3291, 0.6084, 0.7233, 0.3573, 0.6873, 0.5573],\n",
            "         [0.5000, 0.5521, 0.3263, 0.5782, 0.6823, 0.3747, 0.6793, 0.5981],\n",
            "         [0.4960, 0.5416, 0.3366, 0.5809, 0.6887, 0.3882, 0.6706, 0.6010],\n",
            "         [0.5034, 0.5741, 0.3197, 0.5882, 0.7020, 0.3455, 0.6901, 0.5605]]])\n",
            "tensor([[[0.5415, 0.5852, 0.5622, 0.6506, 0.4228, 0.3014, 0.5880, 0.5845],\n",
            "         [0.5435, 0.6083, 0.5669, 0.6708, 0.4330, 0.2850, 0.5912, 0.5998],\n",
            "         [0.5381, 0.5992, 0.5638, 0.6743, 0.4251, 0.3037, 0.5907, 0.5903],\n",
            "         [0.5368, 0.6034, 0.5660, 0.6776, 0.4278, 0.3002, 0.5935, 0.5943]],\n",
            "\n",
            "        [[0.5038, 0.5648, 0.3291, 0.6084, 0.7233, 0.3573, 0.6873, 0.5573],\n",
            "         [0.5000, 0.5521, 0.3263, 0.5782, 0.6823, 0.3747, 0.6793, 0.5981],\n",
            "         [0.4960, 0.5416, 0.3366, 0.5809, 0.6887, 0.3882, 0.6706, 0.6010],\n",
            "         [0.5034, 0.5741, 0.3197, 0.5882, 0.7020, 0.3455, 0.6901, 0.5605]]])\n",
            "tensor([[[1.9985, 2.0000, 3.9985, 2.9970],\n",
            "         [2.0000, 2.0000, 4.0000, 3.0000]]])\n",
            "tensor([[[1.9985, 2.0000, 3.9985, 2.9970],\n",
            "         [2.0000, 2.0000, 4.0000, 3.0000]]])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}